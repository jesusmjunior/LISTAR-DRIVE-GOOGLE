import streamlit as st
from html.parser import HTMLParser
import pandas as pd

# CONFIGURAÃ‡ÃƒO STREAMLIT
st.set_page_config(page_title="ğŸ” Scraping Google Drive ou HTML", layout="centered")
st.title("ğŸ“‚ Google Drive Scraper - Sem BeautifulSoup")

st.markdown("""
## ğŸ‘‹ Bem-vindo!

Este app faz scraping de HTML simples SEM usar BeautifulSoup (sem instalaÃ§Ã£o extra).

Cole abaixo qualquer HTML ou resultado que deseja parsear.
""")

# DEFININDO PARSER NATIVO
class MeuParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.textos = []
        self.links = []

    def handle_data(self, data):
        texto = data.strip()
        if texto:
            self.textos.append(texto)

    def handle_starttag(self, tag, attrs):
        if tag == 'a':
            for attr in attrs:
                if attr[0] == 'href':
                    self.links.append(attr[1])

# INPUT DO USUÃRIO
html_input = st.text_area("ğŸ“¥ Cole aqui o HTML:", "<h1>TÃ­tulo</h1><p>ParÃ¡grafo de exemplo.</p><a href='https://google.com'>Google</a>")

if st.button("ğŸ” Fazer Scraping"):
    parser = MeuParser()
    parser.feed(html_input)
    
    st.subheader("ğŸ¯ Textos ExtraÃ­dos:")
    for texto in parser.textos:
        st.write(f"- {texto}")
    
    st.subheader("ğŸ”— Links Encontrados:")
    for link in parser.links:
        st.write(f"- {link}")
    
    # EXPORTAR PARA XLS
    if parser.textos or parser.links:
        df = pd.DataFrame({
            "Textos": parser.textos,
            "Links": parser.links + [""]*(len(parser.textos) - len(parser.links)) if len(parser.links) < len(parser.textos) else parser.links
        })
        st.download_button("ğŸ“¥ Baixar XLS", df.to_csv(index=False), file_name="resultado_scraping.csv")
